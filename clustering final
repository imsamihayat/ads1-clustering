#importing dictionaries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.cluster as cluster
import sklearn.metrics as skmet
import scipy.optimize as opt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA


def err_ranges(x, func, param, sigma):
    """
    Calculates the upper and lower limits for the function, parameters and
    sigmas for single value or array x. Functions values are calculated for 
    all combinations of +/- sigma and the minimum and maximum is determined.
    Can be used for all number of parameters and sigmas >=1.
    
    This routine can be used in assignment programs.
    """

    import itertools as iter
    
    # initiate arrays for lower and upper limits
    lower = func(x, *param)
    upper = lower
    
    uplow = []   # list to hold upper and lower limits for parameters
    for p,s in zip(param, sigma):
        pmin = p - s
        pmax = p + s
        uplow.append((pmin, pmax))
        
    pmix = list(iter.product(*uplow))
    
    for p in pmix:
        y = func(x, *p)
        lower = np.minimum(lower, y)
        upper = np.maximum(upper, y)
        
    return lower, upper   




df = pd.read_csv('API_19_DS2_en_csv_v2_4700503.csv')

# Removing some unused columns 
df = df.drop(['Unnamed: 66'], axis=1)

# countries metadata

dfc = pd.read_csv('Metadata_Country_API_19_DS2_en_csv_v2_4700503.csv')

# Dropping Extra Income Groups in the Countries list
dfc1 = dfc[~pd.isna(dfc['IncomeGroup'])]

# Indicators which we have selected to do the analysis
indicators_list = ['Population, total','Urban population','Arable land (% of land area)',
                   'Access to electricity (% of population)','CO2 emissions (kt)', 
                   'Forest area (sq. km)', 'Agricultural land (sq. km)']

# Getting the data of selected indicators and of year 2017, 2018 and 2019
new_df = df[df['Indicator Name'].isin(indicators_list)][['Country Name','Indicator Name','2017','2018','2019']]

# Getting the average values of these selected years
new_df['average values'] = new_df[['2017','2018','2019']].mean(axis=1)

# Now Dropping these year values
new_df = new_df.drop(['2017','2018','2019'], axis=1)

df1 = pd.read_csv('API_NY.GDP.PCAP.CD_DS2_en_csv_v2_4770417.csv') # This data shows the GDP per capita
df1.shape

# for the GDP per capita I will select the same years and then calculate the average and then drop these columns.
new_df1 = df1[['Country Name','Indicator Name','2017','2018','2019']]

new_df1['average values'] = new_df1[['2017','2018','2019']].mean(axis=1)

new_df1 = new_df1.drop(['2017','2018','2019'], axis=1)

# Joining both the data.
new_df = pd.concat([new_df,new_df1])

# Grouping by Country and Indicator.
data1 = new_df.groupby(['Country Name','Indicator Name'])['average values'].sum().unstack()

# Merging with the dfc1 dataframe(in which we drop the Income group) 
data1 = data1.merge(dfc1[['TableName']], left_on=data1.index, right_on='TableName', how='inner')
data1.index = data1['TableName']
data1 = data1.drop(['TableName'], axis=1)

# Creating the Correlation graph
plt.figure(figsize=(8,6))
sns.heatmap(data1.corr(), cmap='viridis', linewidths=.5, annot=True)
plt.show()

# Creating the pairplot
sns.pairplot(data1)
plt.tight_layout() # helps to avoid overlap of labels
plt.xticks(rotation=90)
plt.yticks(rotation=90)
plt.show()

  
# Scaling the data using standard scaler
scaler = StandardScaler()
  
# fitting
scaler.fit(data1)
standardized_data = scaler.transform(data1)

# applying the PCA technique to convert the data to 2 feature attributes.
pca = PCA(n_components = 2)
pca.fit(standardized_data)
x_pca = pca.transform(standardized_data)

# Creating Scatter plot of these 2 features.
plt.scatter(x_pca[:,0], x_pca[:,1])
plt.xlabel('1st Feature')
plt.ylabel('2nd Feature')
plt.show()

# creating dataframe with these 2 features.
x_pca = pd.DataFrame(x_pca)
x_pca.index = data1.index


x = x_pca[0]
y = x_pca[1]

# Applying k means clustering. we will apply the clustering with 2,3 and 4 clusters. and will evaluate which clusters are best.
for ncluster in [2,3,4]:

    kmeans = cluster.KMeans(n_clusters=ncluster)
    kmeans.fit(x_pca[[0,1]]) 
    labels = kmeans.labels_
    x_pca.loc[:, 'cluster_' +str(ncluster)+ '_label'] = labels
    
    cen = kmeans.cluster_centers_
    print('Cluster Centers: ',cen)
    # calculate the silhoutte score
    print('Silhouette Score with ' + str(ncluster) +' clusters : '+ str(skmet.silhouette_score(x_pca, labels)))
    # plot using the labels to select colour

    plt.figure(figsize=(6,5))
    col = ["tab:blue", "tab:green", "tab:red", "tab:purple"]
    for l in range(ncluster):
        plt.plot(x[labels==l], y[labels==l], "o", markersize=4, color=col[l])

    for ic in range(ncluster):
        xc, yc = cen[ic,:]
        plt.plot(xc, yc, "dk", markersize=10)
        
    plt.xlabel("x")
    plt.ylabel("y")
    plt.show()

    
print('Total Countries in 1st cluster: ', len(x_pca[x_pca['cluster_3_label']==0].index))
print('Total Countries in 2nd cluster: ', len(x_pca[x_pca['cluster_3_label']==1].index))
print('Total Countries in 3rd cluster: ', len(x_pca[x_pca['cluster_3_label']==2].index))

#So, we are choosing 'Australia' from Cluster 1
#'China' from Cluster 2
#and 'Haiti' from Cluster 3

# creating the exponential and logistic function
def exponential(t, n0, g):
    t = t - 1960.0
    f = n0 * np.exp(g*t)
    return f

def logistic(t, n0, g, t0):
    f = n0 / (1 + np.exp(-g*(t - t0)))
    return f

# applying the Exponential and Logistic function on the selected countries.
for country,p0_exp,p0_log in zip(['Australia','China','Haiti'],[(64588.23, 0.03), (64588.23, 0.03),(1852, 0.03)], [(64588.23, 0.03, 2000), (64588.23, 0.03, 2000),(1852, 0.03, 2000)]):

    df_country = df1[df1['Country Name'] == country].transpose() # taking transpose
    df_country.columns = ['GDP per Capita ($)']
    df_country = df_country.drop(['Country Name','Country Code','Indicator Name','Indicator Code','Unnamed: 66']) # dropping some columns.
    df_country = df_country.reset_index().rename({'index':'Year'}, axis=1)

    # Creating Line plot of each country.
    plt.figure(figsize=(6,4))
    plt.plot(df_country['Year'], df_country['GDP per Capita ($)'])
    plt.xlabel('Year')
    plt.ylabel('GDP per Capita ($)')
    plt.title('GDP per Capita of '+country)
    plt.xticks(['1960','1970','1980','1990','2000','2010','2020'])
    plt.show()

    df_country['Year'] = pd.to_numeric(df_country['Year'])
    df_country['GDP per Capita ($)'] = pd.to_numeric(df_country['GDP per Capita ($)'])

    # applying curve_fit
    parameters_exp, covariance_exp = opt.curve_fit(exponential, df_country["Year"], df_country["GDP per Capita ($)"], 
                                                   p0=p0_exp)

    # sigma_exp
    sigma_exp = np.sqrt(np.diag(covariance_exp))

    # Saving the fit_exponential in the dataframe.
    df_country["fit exponential"] = exponential(df_country["Year"], *parameters_exp)

    # again plotting the line plot and the fitted line.
    plt.figure(figsize=(6,4))
    plt.plot(df_country['Year'], df_country['GDP per Capita ($)'], label='Original Data')
    plt.plot(df_country['Year'], df_country['fit exponential'], label='Fitted Line')
    plt.xlabel('Year')
    plt.ylabel('GDP per Capita ($)')
    plt.title('GDP per Capita of ' + country + ' with fitted line')
    plt.legend()
    plt.show()

    # We will now predict for the years 1960 to 2033. 10 years ahead of the data.
    years_to_pred = np.arange(1960, 2033)

    pred_exp = exponential(years_to_pred, *parameters_exp)

    # finding lower and upper limit.
    lower_limit, upper_limit = err_ranges(years_to_pred, exponential, parameters_exp, sigma_exp)

    # Again creating plot with the Lower and Upper limit.
    plt.figure(figsize=(6,4))
    plt.plot(df_country['Year'], df_country['GDP per Capita ($)'], label='Original Data')
    plt.plot(years_to_pred, pred_exp, label='Fitted Line')
    plt.fill_between(years_to_pred, lower_limit, upper_limit, color="yellow", alpha=0.4)
    plt.xlabel('Year')
    plt.ylabel('GDP per Capita ($)')
    plt.title('GDP per Capita predictions of ' + country + ' with exponential function')
    plt.legend()
    plt.show()

    # Now we will implement same method with logistic function.
    # Logistic Function
    parameters_log, covariance_log = opt.curve_fit(logistic, df_country["Year"], df_country["GDP per Capita ($)"], 
                                        p0=p0_log)

    sigma_log = np.sqrt(np.diag(covariance_log))

    df_country["fit logistic"] = logistic(df_country["Year"], *parameters_log)

    plt.figure(figsize=(6,4))
    plt.plot(df_country['Year'], df_country['GDP per Capita ($)'], label='Original Data')
    plt.plot(df_country['Year'], df_country['fit logistic'], label='Fitted Line')

    plt.xlabel('Year')
    plt.ylabel('GDP per Capita ($)')
    plt.title('GDP per Capita of ' + country + ' with fitted line')
    plt.legend()
    plt.show()

    pred_log = logistic(years_to_pred, *parameters_log)

    lower_limit, upper_limit = err_ranges(years_to_pred, logistic, parameters_log, sigma_log)

    plt.figure(figsize=(6,4))
    plt.plot(df_country['Year'], df_country['GDP per Capita ($)'], label='Original Data')
    plt.plot(years_to_pred, pred_log, label='Fitted Line')
    plt.fill_between(years_to_pred, lower_limit, upper_limit, color="yellow", alpha=0.4)
    plt.xlabel('Year')
    plt.ylabel('GDP per Capita ($)')
    plt.title('GDP per Capita predictions of ' + country + ' with Logistic function')
    plt.legend()
    plt.show()

